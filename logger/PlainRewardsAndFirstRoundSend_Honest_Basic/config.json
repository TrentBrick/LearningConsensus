{
    "ac_kwargs":	{},
    "actor_critic":	"MLPActorCritic",
    "clip_ratio":	0.2,
    "env_fn":	{
        "<MultiAgentEnv instance>":	{
            "action_space":	{
                "Discrete(3)":	{
                    "dtype":	"int64",
                    "n":	3,
                    "np_random":	"RandomState(MT19937)",
                    "shape":	[]
                }
            },
            "agents":	[
                {
                    "<multiagent.core.Honest_Agent object at 0x1c3f66f710>":	{
                        "actionDims":	3,
                        "actionIndex":	null,
                        "actionSpace":	[
                            "send_to_all-value_init",
                            "commit_0",
                            "commit_1"
                        ],
                        "actionString":	"",
                        "action_callback":	null,
                        "agentId":	0,
                        "committed_ptr":	false,
                        "committed_value":	false,
                        "initVal":	"1",
                        "isByzantine":	false,
                        "last_action_etc":	{},
                        "majority_value":	null,
                        "reward":	0,
                        "sentMajority":	false,
                        "state":	"tensor([1, 2, 2], dtype=torch.int32)",
                        "stateDims":	3
                    }
                },
                {
                    "<multiagent.core.Honest_Agent object at 0x1c3f66fa50>":	{
                        "actionDims":	3,
                        "actionIndex":	null,
                        "actionSpace":	[
                            "send_to_all-value_init",
                            "commit_0",
                            "commit_1"
                        ],
                        "actionString":	"",
                        "action_callback":	null,
                        "agentId":	1,
                        "committed_ptr":	false,
                        "committed_value":	false,
                        "initVal":	"1",
                        "isByzantine":	false,
                        "last_action_etc":	{},
                        "majority_value":	null,
                        "reward":	0,
                        "sentMajority":	false,
                        "state":	"tensor([1, 2, 2], dtype=torch.int32)",
                        "stateDims":	3
                    }
                },
                {
                    "<multiagent.core.Honest_Agent object at 0x1c3f66fa90>":	{
                        "actionDims":	3,
                        "actionIndex":	null,
                        "actionSpace":	[
                            "send_to_all-value_init",
                            "commit_0",
                            "commit_1"
                        ],
                        "actionString":	"",
                        "action_callback":	null,
                        "agentId":	2,
                        "committed_ptr":	false,
                        "committed_value":	false,
                        "initVal":	"0",
                        "isByzantine":	false,
                        "last_action_etc":	{},
                        "majority_value":	null,
                        "reward":	0,
                        "sentMajority":	false,
                        "state":	"tensor([0, 2, 2], dtype=torch.int32)",
                        "stateDims":	3
                    }
                }
            ],
            "byzantine_agents":	[],
            "discrete_action_input":	false,
            "discrete_action_space":	true,
            "done_callback":	"is_done",
            "force_discrete_action":	false,
            "honest_agents":	[],
            "info_callback":	null,
            "majorityValue":	1,
            "n":	3,
            "observation_callback":	"observation",
            "observation_space":	{
                "Box(3,)":	{
                    "bounded_above":	"[ True  True  True]",
                    "bounded_below":	"[ True  True  True]",
                    "dtype":	"uint8",
                    "high":	"[2 2 2]",
                    "low":	"[0 0 0]",
                    "np_random":	"RandomState(MT19937)",
                    "shape":	[
                        3
                    ]
                }
            },
            "params":	{
                "LOAD_PATH_EXPERIMENT":	"saved_models/",
                "actions_per_epoch":	6000,
                "activation":	"tanh",
                "additional_round_penalty":	-0.1,
                "additional_round_reward":	0.3,
                "batch_size":	32,
                "byz_honest_train_ratio":	1,
                "byz_starting_temp":	6.0,
                "clip_ratio":	0.2,
                "commit_vals":	[
                    0,
                    1
                ],
                "consistency_violation":	-3.0,
                "correct_commit":	1.1,
                "create_conflicting_state":	0.5,
                "directory":	"runs/",
                "epochs":	200,
                "exp_name":	"PlainRewardsAndFirstRoundSend_Honest_Basic",
                "gamma":	0.99,
                "hidden_sizes":	[
                    16,
                    8
                ],
                "honest_can_send_either_value":	false,
                "honest_correct_commit":	-1,
                "honest_incorrect_commit":	1,
                "honest_starting_temp":	6.0,
                "lam":	0.95,
                "learning_rate":	0.003,
                "load_policy_byz":	"None",
                "load_policy_honest":	"None",
                "logger_dir":	"logger/",
                "majority_violation":	-0.0,
                "max_round_len":	80,
                "ncores":	1,
                "no_conflicting_state":	-0.3,
                "no_send_all_first_round_penalty":	-1.0,
                "null_message_val":	2,
                "num_agents":	3,
                "num_byzantine":	1,
                "output_activation":	null,
                "print_every":	5,
                "random_seed":	27,
                "rl_algo_wanted":	"vpg",
                "sample_k_size":	2,
                "save_freq":	10,
                "scenario":	"honest_basic",
                "send_all_first_round_reward":	3.0,
                "send_incorrect_majority_value_penalty":	-0.3,
                "send_majority_value_reward":	0.6,
                "starting_ep":	1,
                "target_kl":	0.01,
                "temp_anneal":	0.985,
                "temp_fix_point":	1.0,
                "termination_penalty":	-1000.0,
                "train_byz":	true,
                "train_honest":	true,
                "train_policy_iters":	80,
                "train_vf_iters":	80,
                "use_PKI":	false,
                "use_bias":	true,
                "use_heat_jumps":	false,
                "use_vpg":	false,
                "validity_violation":	-3.0,
                "vf_lr":	0.001,
                "vpg_epochs_ratio":	2
            },
            "reset_callback":	"reset_world",
            "reward_callback":	"reward",
            "shared_reward":	false,
            "time":	0,
            "world":	{
                "<multiagent.core.World object at 0x1c3f663310>":	{
                    "agents":	[
                        {
                            "<multiagent.core.Honest_Agent object at 0x1c3f66f710>":	{
                                "actionDims":	3,
                                "actionIndex":	null,
                                "actionSpace":	[
                                    "send_to_all-value_init",
                                    "commit_0",
                                    "commit_1"
                                ],
                                "actionString":	"",
                                "action_callback":	null,
                                "agentId":	0,
                                "committed_ptr":	false,
                                "committed_value":	false,
                                "initVal":	"1",
                                "isByzantine":	false,
                                "last_action_etc":	{},
                                "majority_value":	null,
                                "reward":	0,
                                "sentMajority":	false,
                                "state":	"tensor([1, 2, 2], dtype=torch.int32)",
                                "stateDims":	3
                            }
                        },
                        {
                            "<multiagent.core.Honest_Agent object at 0x1c3f66fa50>":	{
                                "actionDims":	3,
                                "actionIndex":	null,
                                "actionSpace":	[
                                    "send_to_all-value_init",
                                    "commit_0",
                                    "commit_1"
                                ],
                                "actionString":	"",
                                "action_callback":	null,
                                "agentId":	1,
                                "committed_ptr":	false,
                                "committed_value":	false,
                                "initVal":	"1",
                                "isByzantine":	false,
                                "last_action_etc":	{},
                                "majority_value":	null,
                                "reward":	0,
                                "sentMajority":	false,
                                "state":	"tensor([1, 2, 2], dtype=torch.int32)",
                                "stateDims":	3
                            }
                        },
                        {
                            "<multiagent.core.Honest_Agent object at 0x1c3f66fa90>":	{
                                "actionDims":	3,
                                "actionIndex":	null,
                                "actionSpace":	[
                                    "send_to_all-value_init",
                                    "commit_0",
                                    "commit_1"
                                ],
                                "actionString":	"",
                                "action_callback":	null,
                                "agentId":	2,
                                "committed_ptr":	false,
                                "committed_value":	false,
                                "initVal":	"0",
                                "isByzantine":	false,
                                "last_action_etc":	{},
                                "majority_value":	null,
                                "reward":	0,
                                "sentMajority":	false,
                                "state":	"tensor([0, 2, 2], dtype=torch.int32)",
                                "stateDims":	3
                            }
                        }
                    ],
                    "byzantine_agents":	[],
                    "honest_agents":	[],
                    "majorityValue":	1,
                    "params":	{
                        "LOAD_PATH_EXPERIMENT":	"saved_models/",
                        "actions_per_epoch":	6000,
                        "activation":	"tanh",
                        "additional_round_penalty":	-0.1,
                        "additional_round_reward":	0.3,
                        "batch_size":	32,
                        "byz_honest_train_ratio":	1,
                        "byz_starting_temp":	6.0,
                        "clip_ratio":	0.2,
                        "commit_vals":	[
                            0,
                            1
                        ],
                        "consistency_violation":	-3.0,
                        "correct_commit":	1.1,
                        "create_conflicting_state":	0.5,
                        "directory":	"runs/",
                        "epochs":	200,
                        "exp_name":	"PlainRewardsAndFirstRoundSend_Honest_Basic",
                        "gamma":	0.99,
                        "hidden_sizes":	[
                            16,
                            8
                        ],
                        "honest_can_send_either_value":	false,
                        "honest_correct_commit":	-1,
                        "honest_incorrect_commit":	1,
                        "honest_starting_temp":	6.0,
                        "lam":	0.95,
                        "learning_rate":	0.003,
                        "load_policy_byz":	"None",
                        "load_policy_honest":	"None",
                        "logger_dir":	"logger/",
                        "majority_violation":	-0.0,
                        "max_round_len":	80,
                        "ncores":	1,
                        "no_conflicting_state":	-0.3,
                        "no_send_all_first_round_penalty":	-1.0,
                        "null_message_val":	2,
                        "num_agents":	3,
                        "num_byzantine":	1,
                        "output_activation":	null,
                        "print_every":	5,
                        "random_seed":	27,
                        "rl_algo_wanted":	"vpg",
                        "sample_k_size":	2,
                        "save_freq":	10,
                        "scenario":	"honest_basic",
                        "send_all_first_round_reward":	3.0,
                        "send_incorrect_majority_value_penalty":	-0.3,
                        "send_majority_value_reward":	0.6,
                        "starting_ep":	1,
                        "target_kl":	0.01,
                        "temp_anneal":	0.985,
                        "temp_fix_point":	1.0,
                        "termination_penalty":	-1000.0,
                        "train_byz":	true,
                        "train_honest":	true,
                        "train_policy_iters":	80,
                        "train_vf_iters":	80,
                        "use_PKI":	false,
                        "use_bias":	true,
                        "use_heat_jumps":	false,
                        "use_vpg":	false,
                        "validity_violation":	-3.0,
                        "vf_lr":	0.001,
                        "vpg_epochs_ratio":	2
                    }
                }
            }
        }
    },
    "epochs":	200,
    "gamma":	0.99,
    "lam":	0.97,
    "logger":	{
        "<spinup.utils.logx.EpochLogger object at 0x1c3f6935d0>":	{
            "epoch_dict":	{},
            "exp_name":	null,
            "first_row":	true,
            "log_current_row":	{},
            "log_headers":	[],
            "output_dir":	"logger//PlainRewardsAndFirstRoundSend_Honest_Basic",
            "output_file":	{
                "<_io.TextIOWrapper name='logger//PlainRewardsAndFirstRoundSend_Honest_Basic/progress.txt' mode='w' encoding='UTF-8'>":	{
                    "mode":	"w"
                }
            }
        }
    },
    "logger_kwargs":	{},
    "max_ep_len":	1000,
    "params":	{
        "LOAD_PATH_EXPERIMENT":	"saved_models/",
        "actions_per_epoch":	6000,
        "activation":	"tanh",
        "additional_round_penalty":	-0.1,
        "additional_round_reward":	0.3,
        "batch_size":	32,
        "byz_honest_train_ratio":	1,
        "byz_starting_temp":	6.0,
        "clip_ratio":	0.2,
        "commit_vals":	[
            0,
            1
        ],
        "consistency_violation":	-3.0,
        "correct_commit":	1.1,
        "create_conflicting_state":	0.5,
        "directory":	"runs/",
        "epochs":	200,
        "exp_name":	"PlainRewardsAndFirstRoundSend_Honest_Basic",
        "gamma":	0.99,
        "hidden_sizes":	[
            16,
            8
        ],
        "honest_can_send_either_value":	false,
        "honest_correct_commit":	-1,
        "honest_incorrect_commit":	1,
        "honest_starting_temp":	6.0,
        "lam":	0.95,
        "learning_rate":	0.003,
        "load_policy_byz":	"None",
        "load_policy_honest":	"None",
        "logger_dir":	"logger/",
        "majority_violation":	-0.0,
        "max_round_len":	80,
        "ncores":	1,
        "no_conflicting_state":	-0.3,
        "no_send_all_first_round_penalty":	-1.0,
        "null_message_val":	2,
        "num_agents":	3,
        "num_byzantine":	1,
        "output_activation":	null,
        "print_every":	5,
        "random_seed":	27,
        "rl_algo_wanted":	"vpg",
        "sample_k_size":	2,
        "save_freq":	10,
        "scenario":	"honest_basic",
        "send_all_first_round_reward":	3.0,
        "send_incorrect_majority_value_penalty":	-0.3,
        "send_majority_value_reward":	0.6,
        "starting_ep":	1,
        "target_kl":	0.01,
        "temp_anneal":	0.985,
        "temp_fix_point":	1.0,
        "termination_penalty":	-1000.0,
        "train_byz":	true,
        "train_honest":	true,
        "train_policy_iters":	80,
        "train_vf_iters":	80,
        "use_PKI":	false,
        "use_bias":	true,
        "use_heat_jumps":	false,
        "use_vpg":	false,
        "validity_violation":	-3.0,
        "vf_lr":	0.001,
        "vpg_epochs_ratio":	2
    },
    "pi_lr":	0.0003,
    "save_freq":	5,
    "seed":	0,
    "steps_per_epoch":	6000.0,
    "target_kl":	0.01,
    "train_pi_iters":	80,
    "train_v_iters":	80,
    "vf_lr":	0.001
}