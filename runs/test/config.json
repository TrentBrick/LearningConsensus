{
    "ac_kwargs":	{},
    "actor_critic":	"MLPActorCritic",
    "clip_ratio":	0.2,
    "env_fn":	{
        "<MultiAgentEnv instance>":	{
            "action_space":	{
                "Discrete(9)":	{
                    "dtype":	"int64",
                    "n":	9,
                    "np_random":	"RandomState(MT19937)",
                    "shape":	[]
                }
            },
            "agents":	[
                {
                    "<multiagent.core_sync_BA.Byzantine_Agent object at 0x7ff848841e90>":	{
                        "actionDims":	9,
                        "actionIndex":	null,
                        "actionSpace":	[
                            "no_send",
                            "send_agent-0_v-0",
                            "send_agent-0_v-1",
                            "send_agent-2_v-0",
                            "send_agent-2_v-1",
                            "send_agent-0_v-0_agent-2_v-1",
                            "send_agent-0_v-0_agent-2_v-0",
                            "send_agent-0_v-1_agent-2_v-0",
                            "send_agent-0_v-1_agent-2_v-1"
                        ],
                        "actionString":	"",
                        "action_callback":	null,
                        "agentId":	1,
                        "committed_ptr":	false,
                        "committed_value":	2,
                        "isByzantine":	true,
                        "isLeader":	true,
                        "last_action_etc":	{},
                        "prevActionString":	"",
                        "proposeValue":	2,
                        "reward":	0,
                        "state":	"tensor([2, 2, 2, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)",
                        "stateDims":	3,
                        "statusValue":	2,
                        "status_values":	[]
                    }
                }
            ],
            "allAgents":	[
                {
                    "<multiagent.core_sync_BA.Honest_Agent object at 0x7ff848841e10>":	{
                        "actionIndex":	null,
                        "actionString":	"",
                        "action_callback":	true,
                        "agentId":	0,
                        "committed_ptr":	false,
                        "committed_value":	2,
                        "isByzantine":	false,
                        "isLeader":	false,
                        "last_action_etc":	{},
                        "proposeValue":	2,
                        "reward":	0,
                        "roundValue":	2,
                        "state":	"tensor([2, 2, 2], dtype=torch.int32)",
                        "stateDims":	3,
                        "statusValue":	2,
                        "status_values":	[]
                    }
                },
                {
                    "<multiagent.core_sync_BA.Honest_Agent object at 0x7ff848841dd0>":	{
                        "actionIndex":	null,
                        "actionString":	"",
                        "action_callback":	true,
                        "agentId":	2,
                        "committed_ptr":	false,
                        "committed_value":	2,
                        "isByzantine":	false,
                        "isLeader":	false,
                        "last_action_etc":	{},
                        "proposeValue":	2,
                        "reward":	0,
                        "roundValue":	2,
                        "state":	"tensor([2, 2, 2], dtype=torch.int32)",
                        "stateDims":	3,
                        "statusValue":	2,
                        "status_values":	[]
                    }
                },
                {
                    "<multiagent.core_sync_BA.Byzantine_Agent object at 0x7ff848841e90>":	{
                        "actionDims":	9,
                        "actionIndex":	null,
                        "actionSpace":	[
                            "no_send",
                            "send_agent-0_v-0",
                            "send_agent-0_v-1",
                            "send_agent-2_v-0",
                            "send_agent-2_v-1",
                            "send_agent-0_v-0_agent-2_v-1",
                            "send_agent-0_v-0_agent-2_v-0",
                            "send_agent-0_v-1_agent-2_v-0",
                            "send_agent-0_v-1_agent-2_v-1"
                        ],
                        "actionString":	"",
                        "action_callback":	null,
                        "agentId":	1,
                        "committed_ptr":	false,
                        "committed_value":	2,
                        "isByzantine":	true,
                        "isLeader":	true,
                        "last_action_etc":	{},
                        "prevActionString":	"",
                        "proposeValue":	2,
                        "reward":	0,
                        "state":	"tensor([2, 2, 2, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)",
                        "stateDims":	3,
                        "statusValue":	2,
                        "status_values":	[]
                    }
                }
            ],
            "byzantine_agents":	[
                {
                    "<multiagent.core_sync_BA.Byzantine_Agent object at 0x7ff848841e90>":	{
                        "actionDims":	9,
                        "actionIndex":	null,
                        "actionSpace":	[
                            "no_send",
                            "send_agent-0_v-0",
                            "send_agent-0_v-1",
                            "send_agent-2_v-0",
                            "send_agent-2_v-1",
                            "send_agent-0_v-0_agent-2_v-1",
                            "send_agent-0_v-0_agent-2_v-0",
                            "send_agent-0_v-1_agent-2_v-0",
                            "send_agent-0_v-1_agent-2_v-1"
                        ],
                        "actionString":	"",
                        "action_callback":	null,
                        "agentId":	1,
                        "committed_ptr":	false,
                        "committed_value":	2,
                        "isByzantine":	true,
                        "isLeader":	true,
                        "last_action_etc":	{},
                        "prevActionString":	"",
                        "proposeValue":	2,
                        "reward":	0,
                        "state":	"tensor([2, 2, 2, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)",
                        "stateDims":	3,
                        "statusValue":	2,
                        "status_values":	[]
                    }
                }
            ],
            "discrete_action_input":	false,
            "discrete_action_space":	true,
            "done_callback":	"is_done",
            "force_discrete_action":	false,
            "honest_agents":	[
                {
                    "<multiagent.core_sync_BA.Honest_Agent object at 0x7ff848841e10>":	{
                        "actionIndex":	null,
                        "actionString":	"",
                        "action_callback":	true,
                        "agentId":	0,
                        "committed_ptr":	false,
                        "committed_value":	2,
                        "isByzantine":	false,
                        "isLeader":	false,
                        "last_action_etc":	{},
                        "proposeValue":	2,
                        "reward":	0,
                        "roundValue":	2,
                        "state":	"tensor([2, 2, 2], dtype=torch.int32)",
                        "stateDims":	3,
                        "statusValue":	2,
                        "status_values":	[]
                    }
                },
                {
                    "<multiagent.core_sync_BA.Honest_Agent object at 0x7ff848841dd0>":	{
                        "actionIndex":	null,
                        "actionString":	"",
                        "action_callback":	true,
                        "agentId":	2,
                        "committed_ptr":	false,
                        "committed_value":	2,
                        "isByzantine":	false,
                        "isLeader":	false,
                        "last_action_etc":	{},
                        "proposeValue":	2,
                        "reward":	0,
                        "roundValue":	2,
                        "state":	"tensor([2, 2, 2], dtype=torch.int32)",
                        "stateDims":	3,
                        "statusValue":	2,
                        "status_values":	[]
                    }
                }
            ],
            "info_callback":	null,
            "leader":	{
                "<multiagent.core_sync_BA.Byzantine_Agent object at 0x7ff848841e90>":	{
                    "actionDims":	9,
                    "actionIndex":	null,
                    "actionSpace":	[
                        "no_send",
                        "send_agent-0_v-0",
                        "send_agent-0_v-1",
                        "send_agent-2_v-0",
                        "send_agent-2_v-1",
                        "send_agent-0_v-0_agent-2_v-1",
                        "send_agent-0_v-0_agent-2_v-0",
                        "send_agent-0_v-1_agent-2_v-0",
                        "send_agent-0_v-1_agent-2_v-1"
                    ],
                    "actionString":	"",
                    "action_callback":	null,
                    "agentId":	1,
                    "committed_ptr":	false,
                    "committed_value":	2,
                    "isByzantine":	true,
                    "isLeader":	true,
                    "last_action_etc":	{},
                    "prevActionString":	"",
                    "proposeValue":	2,
                    "reward":	0,
                    "state":	"tensor([2, 2, 2, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)",
                    "stateDims":	3,
                    "statusValue":	2,
                    "status_values":	[]
                }
            },
            "majorityValue":	-1,
            "n":	3,
            "observation_callback":	"observation",
            "observation_space":	{
                "Box(14,)":	{
                    "bounded_above":	"[ True  True  True  True  True  True  True  True  True  True  True  True\n  True  True]",
                    "bounded_below":	"[ True  True  True  True  True  True  True  True  True  True  True  True\n  True  True]",
                    "dtype":	"uint8",
                    "high":	"[3 3 3 3 3 3 3 3 3 3 3 3 3 3]",
                    "low":	"[0 0 0 0 0 0 0 0 0 0 0 0 0 0]",
                    "np_random":	"RandomState(MT19937)",
                    "shape":	[
                        14
                    ]
                }
            },
            "params":	{
                "LOAD_PATH_EXPERIMENT":	"saved_models/",
                "PKI_penalty":	-1,
                "PKI_reward":	0.25,
                "actions_per_epoch":	4000,
                "activation":	"tanh",
                "additional_round_penalty":	-0.1,
                "additional_round_reward":	0.3,
                "batch_size":	32,
                "byz_honest_train_ratio":	1,
                "byz_starting_temp":	6.0,
                "clip_ratio":	0.2,
                "commit_vals":	[
                    0,
                    1
                ],
                "consistency_violation":	-3.0,
                "correct_commit":	-1.0,
                "directory":	"runs/",
                "epochs":	100,
                "equivocation_penalty":	-0.3,
                "exp_name":	"TestRun",
                "first_round_reward":	0,
                "gamma":	0.99,
                "hidden_sizes":	[
                    16,
                    8
                ],
                "honest_can_send_either_value":	false,
                "honest_correct_commit":	-500,
                "honest_incorrect_commit":	1,
                "honest_starting_temp":	6.0,
                "incorrect_commit":	1.0,
                "lam":	0.95,
                "learning_rate":	0.003,
                "load_policy_byz":	"None",
                "load_policy_honest":	"None",
                "logger_dir":	"logger/",
                "majority_violation":	-25.0,
                "max_round_len":	32,
                "ncores":	1,
                "no_equivocation_reward":	0.3,
                "no_send_all_first_round_penalty":	-1.0,
                "null_message_val":	2,
                "num_agents":	3,
                "num_byzantine":	1,
                "output_activation":	null,
                "print_every":	5,
                "random_seed":	27,
                "rl_algo_wanted":	"vpg",
                "safety_reward":	500,
                "sample_k_size":	2,
                "save_freq":	10,
                "scenario":	"sync_BA",
                "send_all_first_round_reward":	0.3,
                "send_incorrect_majority_value_penalty":	-0.3,
                "send_majority_value_reward":	0.6,
                "starting_ep":	1,
                "target_kl":	0.01,
                "temp_anneal":	0.985,
                "temp_fix_point":	1.0,
                "termination_penalty":	-3.0,
                "termination_reward":	0,
                "train_byz":	true,
                "train_honest":	true,
                "train_policy_iters":	80,
                "train_vf_iters":	80,
                "use_PKI":	false,
                "use_bias":	true,
                "use_heat_jumps":	false,
                "use_vpg":	false,
                "validity_violation":	-3.0,
                "vf_lr":	0.001,
                "vpg_epochs_ratio":	2
            },
            "reset_callback":	"reset_world",
            "reward_callback":	"reward",
            "shared_reward":	false,
            "time":	0,
            "world":	{
                "<multiagent.core_sync_BA.World object at 0x7ff8649f4190>":	{
                    "agents":	[
                        {
                            "<multiagent.core_sync_BA.Honest_Agent object at 0x7ff848841e10>":	{
                                "actionIndex":	null,
                                "actionString":	"",
                                "action_callback":	true,
                                "agentId":	0,
                                "committed_ptr":	false,
                                "committed_value":	2,
                                "isByzantine":	false,
                                "isLeader":	false,
                                "last_action_etc":	{},
                                "proposeValue":	2,
                                "reward":	0,
                                "roundValue":	2,
                                "state":	"tensor([2, 2, 2], dtype=torch.int32)",
                                "stateDims":	3,
                                "statusValue":	2,
                                "status_values":	[]
                            }
                        },
                        {
                            "<multiagent.core_sync_BA.Honest_Agent object at 0x7ff848841dd0>":	{
                                "actionIndex":	null,
                                "actionString":	"",
                                "action_callback":	true,
                                "agentId":	2,
                                "committed_ptr":	false,
                                "committed_value":	2,
                                "isByzantine":	false,
                                "isLeader":	false,
                                "last_action_etc":	{},
                                "proposeValue":	2,
                                "reward":	0,
                                "roundValue":	2,
                                "state":	"tensor([2, 2, 2], dtype=torch.int32)",
                                "stateDims":	3,
                                "statusValue":	2,
                                "status_values":	[]
                            }
                        },
                        {
                            "<multiagent.core_sync_BA.Byzantine_Agent object at 0x7ff848841e90>":	{
                                "actionDims":	9,
                                "actionIndex":	null,
                                "actionSpace":	[
                                    "no_send",
                                    "send_agent-0_v-0",
                                    "send_agent-0_v-1",
                                    "send_agent-2_v-0",
                                    "send_agent-2_v-1",
                                    "send_agent-0_v-0_agent-2_v-1",
                                    "send_agent-0_v-0_agent-2_v-0",
                                    "send_agent-0_v-1_agent-2_v-0",
                                    "send_agent-0_v-1_agent-2_v-1"
                                ],
                                "actionString":	"",
                                "action_callback":	null,
                                "agentId":	1,
                                "committed_ptr":	false,
                                "committed_value":	2,
                                "isByzantine":	true,
                                "isLeader":	true,
                                "last_action_etc":	{},
                                "prevActionString":	"",
                                "proposeValue":	2,
                                "reward":	0,
                                "state":	"tensor([2, 2, 2, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)",
                                "stateDims":	3,
                                "statusValue":	2,
                                "status_values":	[]
                            }
                        }
                    ],
                    "byzantineEquivocate":	false,
                    "byzantine_agents":	[
                        {
                            "<multiagent.core_sync_BA.Byzantine_Agent object at 0x7ff848841e90>":	{
                                "actionDims":	9,
                                "actionIndex":	null,
                                "actionSpace":	[
                                    "no_send",
                                    "send_agent-0_v-0",
                                    "send_agent-0_v-1",
                                    "send_agent-2_v-0",
                                    "send_agent-2_v-1",
                                    "send_agent-0_v-0_agent-2_v-1",
                                    "send_agent-0_v-0_agent-2_v-0",
                                    "send_agent-0_v-1_agent-2_v-0",
                                    "send_agent-0_v-1_agent-2_v-1"
                                ],
                                "actionString":	"",
                                "action_callback":	null,
                                "agentId":	1,
                                "committed_ptr":	false,
                                "committed_value":	2,
                                "isByzantine":	true,
                                "isLeader":	true,
                                "last_action_etc":	{},
                                "prevActionString":	"",
                                "proposeValue":	2,
                                "reward":	0,
                                "state":	"tensor([2, 2, 2, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)",
                                "stateDims":	3,
                                "statusValue":	2,
                                "status_values":	[]
                            }
                        }
                    ],
                    "honest_agents":	[
                        {
                            "<multiagent.core_sync_BA.Honest_Agent object at 0x7ff848841e10>":	{
                                "actionIndex":	null,
                                "actionString":	"",
                                "action_callback":	true,
                                "agentId":	0,
                                "committed_ptr":	false,
                                "committed_value":	2,
                                "isByzantine":	false,
                                "isLeader":	false,
                                "last_action_etc":	{},
                                "proposeValue":	2,
                                "reward":	0,
                                "roundValue":	2,
                                "state":	"tensor([2, 2, 2], dtype=torch.int32)",
                                "stateDims":	3,
                                "statusValue":	2,
                                "status_values":	[]
                            }
                        },
                        {
                            "<multiagent.core_sync_BA.Honest_Agent object at 0x7ff848841dd0>":	{
                                "actionIndex":	null,
                                "actionString":	"",
                                "action_callback":	true,
                                "agentId":	2,
                                "committed_ptr":	false,
                                "committed_value":	2,
                                "isByzantine":	false,
                                "isLeader":	false,
                                "last_action_etc":	{},
                                "proposeValue":	2,
                                "reward":	0,
                                "roundValue":	2,
                                "state":	"tensor([2, 2, 2], dtype=torch.int32)",
                                "stateDims":	3,
                                "statusValue":	2,
                                "status_values":	[]
                            }
                        }
                    ],
                    "majorityValue":	-1,
                    "params":	{
                        "LOAD_PATH_EXPERIMENT":	"saved_models/",
                        "PKI_penalty":	-1,
                        "PKI_reward":	0.25,
                        "actions_per_epoch":	4000,
                        "activation":	"tanh",
                        "additional_round_penalty":	-0.1,
                        "additional_round_reward":	0.3,
                        "batch_size":	32,
                        "byz_honest_train_ratio":	1,
                        "byz_starting_temp":	6.0,
                        "clip_ratio":	0.2,
                        "commit_vals":	[
                            0,
                            1
                        ],
                        "consistency_violation":	-3.0,
                        "correct_commit":	-1.0,
                        "directory":	"runs/",
                        "epochs":	100,
                        "equivocation_penalty":	-0.3,
                        "exp_name":	"TestRun",
                        "first_round_reward":	0,
                        "gamma":	0.99,
                        "hidden_sizes":	[
                            16,
                            8
                        ],
                        "honest_can_send_either_value":	false,
                        "honest_correct_commit":	-500,
                        "honest_incorrect_commit":	1,
                        "honest_starting_temp":	6.0,
                        "incorrect_commit":	1.0,
                        "lam":	0.95,
                        "learning_rate":	0.003,
                        "load_policy_byz":	"None",
                        "load_policy_honest":	"None",
                        "logger_dir":	"logger/",
                        "majority_violation":	-25.0,
                        "max_round_len":	32,
                        "ncores":	1,
                        "no_equivocation_reward":	0.3,
                        "no_send_all_first_round_penalty":	-1.0,
                        "null_message_val":	2,
                        "num_agents":	3,
                        "num_byzantine":	1,
                        "output_activation":	null,
                        "print_every":	5,
                        "random_seed":	27,
                        "rl_algo_wanted":	"vpg",
                        "safety_reward":	500,
                        "sample_k_size":	2,
                        "save_freq":	10,
                        "scenario":	"sync_BA",
                        "send_all_first_round_reward":	0.3,
                        "send_incorrect_majority_value_penalty":	-0.3,
                        "send_majority_value_reward":	0.6,
                        "starting_ep":	1,
                        "target_kl":	0.01,
                        "temp_anneal":	0.985,
                        "temp_fix_point":	1.0,
                        "termination_penalty":	-3.0,
                        "termination_reward":	0,
                        "train_byz":	true,
                        "train_honest":	true,
                        "train_policy_iters":	80,
                        "train_vf_iters":	80,
                        "use_PKI":	false,
                        "use_bias":	true,
                        "use_heat_jumps":	false,
                        "use_vpg":	false,
                        "validity_violation":	-3.0,
                        "vf_lr":	0.001,
                        "vpg_epochs_ratio":	2
                    }
                }
            }
        }
    },
    "epochs":	100,
    "gamma":	0.99,
    "lam":	0.97,
    "logger":	{
        "<spinup.utils.logx.EpochLogger object at 0x7ff8488623d0>":	{
            "epoch_dict":	{},
            "exp_name":	null,
            "first_row":	true,
            "log_current_row":	{},
            "log_headers":	[],
            "output_dir":	"runs/test",
            "output_file":	{
                "<_io.TextIOWrapper name='runs/test/progress.txt' mode='w' encoding='UTF-8'>":	{
                    "mode":	"w"
                }
            }
        }
    },
    "logger_kwargs":	{},
    "max_ep_len":	1000,
    "params":	{
        "LOAD_PATH_EXPERIMENT":	"saved_models/",
        "PKI_penalty":	-1,
        "PKI_reward":	0.25,
        "actions_per_epoch":	4000,
        "activation":	"tanh",
        "additional_round_penalty":	-0.1,
        "additional_round_reward":	0.3,
        "batch_size":	32,
        "byz_honest_train_ratio":	1,
        "byz_starting_temp":	6.0,
        "clip_ratio":	0.2,
        "commit_vals":	[
            0,
            1
        ],
        "consistency_violation":	-3.0,
        "correct_commit":	-1.0,
        "directory":	"runs/",
        "epochs":	100,
        "equivocation_penalty":	-0.3,
        "exp_name":	"TestRun",
        "first_round_reward":	0,
        "gamma":	0.99,
        "hidden_sizes":	[
            16,
            8
        ],
        "honest_can_send_either_value":	false,
        "honest_correct_commit":	-500,
        "honest_incorrect_commit":	1,
        "honest_starting_temp":	6.0,
        "incorrect_commit":	1.0,
        "lam":	0.95,
        "learning_rate":	0.003,
        "load_policy_byz":	"None",
        "load_policy_honest":	"None",
        "logger_dir":	"logger/",
        "majority_violation":	-25.0,
        "max_round_len":	32,
        "ncores":	1,
        "no_equivocation_reward":	0.3,
        "no_send_all_first_round_penalty":	-1.0,
        "null_message_val":	2,
        "num_agents":	3,
        "num_byzantine":	1,
        "output_activation":	null,
        "print_every":	5,
        "random_seed":	27,
        "rl_algo_wanted":	"vpg",
        "safety_reward":	500,
        "sample_k_size":	2,
        "save_freq":	10,
        "scenario":	"sync_BA",
        "send_all_first_round_reward":	0.3,
        "send_incorrect_majority_value_penalty":	-0.3,
        "send_majority_value_reward":	0.6,
        "starting_ep":	1,
        "target_kl":	0.01,
        "temp_anneal":	0.985,
        "temp_fix_point":	1.0,
        "termination_penalty":	-3.0,
        "termination_reward":	0,
        "train_byz":	true,
        "train_honest":	true,
        "train_policy_iters":	80,
        "train_vf_iters":	80,
        "use_PKI":	false,
        "use_bias":	true,
        "use_heat_jumps":	false,
        "use_vpg":	false,
        "validity_violation":	-3.0,
        "vf_lr":	0.001,
        "vpg_epochs_ratio":	2
    },
    "pi_lr":	0.0003,
    "save_freq":	5,
    "seed":	0,
    "steps_per_epoch":	4000.0,
    "target_kl":	0.01,
    "train_pi_iters":	80,
    "train_v_iters":	80,
    "vf_lr":	0.001
}